# input {
#   file {
#     #https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html
#     #default is TAIL which assumes more data will come into the file.
#     #change to mode => "read" if the file is a complete file.  
#     #by default, the file will be removed once reading is complete -- backup your files if you need them.
#     # we will be using READ with the completed file action to log to a file.
#     mode => "read"
#     path => "/usr/share/logstash/ingest_data/*.log" #specifying only csv files.
#     # exit_after_read => true # this tells logstash to exit after reading the file.  This is useful for running logstash as a "job". if you want logstash to continue to run and monitor for files, remove this line.
#     file_completed_action => "log" # this tells logstash to log to the file specified in file_completed_log_path once its done reading the input file.
#     file_completed_log_path => "/usr/share/logstash/ingest_data/logstash_completed.log"
#   }
# }

input {
  jdbc {
    jdbc_driver_library => "/usr/share/java/postgresql-42.7.2.jar"
    jdbc_driver_class => "org.postgresql.Driver"
    jdbc_connection_string => "jdbc:postgresql://postgres:5432/transcendence"
    jdbc_user => "transcendencer"
    jdbc_password => "transcendencer"
    # parameters => {
    #   "post_author" => "1"
    #   "admin" => "admin"
    #   "user" => "user"
    #   }
    schedule => "*/1 * * * *"
    statement => "select * from users_customuser;"# where comment_author = :admin;"
    # statement => "select * from wp_comments where comment_author = :admin;"
  }
  # redis {
  #   host => "redis"
  #   port => 6379
  #   data_type => "channel"
  #   key => "*"
  #   # key => "ZP(k/X?;~I=cqqL<cTTH^n_Vn;VAJsSR)5SF)964!P@~7T%&3[Vr+cV/^1M!^boS"
  #   # key => "ZP(k/X?;~I=cqqL<cTTH^n_Vn;VAJsSR)5SF)964!P@~7T%&3[Vr+cV/^1M!^boSwp:posts:7"
  #   # password => "your_redis_password"
  #   # codec => json
  # }
}


# filter {
#   if [type] == "jdbc" {
#     mutate {
#       add_field => { "[@metadata][index]" => "mysql_index0" }
#     }
#   }
#   if [type] == "redis" {
#     mutate {
#       add_field => { "[@metadata][index]" => "redis_index0" }
#     }
#   }
# }


# filter {
#   if [post_date_gmt] == '0000-00-00' or [post_date_gmt] == '' {
#     mutate {
#       remove_field => ["post_date_gmt"]
#     }
#   }
# }

# filter {
#   mutate {
#     gsub => [ "post_date_gmt", "0000-00-00", "2025-01-01" ]
#   }
# }

output {
  elasticsearch {
    # index => "mysql0-index-logstash-%{+YYYY.MM.dd}"
    index => "postgres_index-%{+YYYY.MM.dd}"
    # index => ["mysql0-index-logstash-%{+YYYY.MM.dd}", "redis0-index-logstash-%{+YYYY.MM.dd}"]
    # index => "%{[@metadata][index]}"
    # index => "%{[type] == 'jdbc' ? 'mysql_index0' : 'redis_index0'}"
    hosts=> "${ELASTIC_HOSTS}"
    user=> "${ELASTIC_USER}"
    password=> "${ELASTIC_PASSWORD}"
    cacert=> "certs/ca/ca.crt"
  }
}
